# SIA: Semantic Integrity Agent

A user-side AI companion that detects and alerts when language inputs may be steering, reframing, or gradually rewriting the user's values or beliefs.

## ğŸ¯ Purpose

To defend users from imperceptible shifts in worldview caused by persuasive language, emotional priming, or semantic mirroring by advanced LLMs.

## ğŸ›  Key Capabilities

1. **Framing Shift Detection**
Â  Â - Flags rewordings that alter meaning without changing facts.
Â  Â - Example: â€œHe made a mistakeâ€ â†’ â€œHe betrayed us.â€

2. **Emotional Payload Alerts**
Â  Â - Warns when emotional content ramps up to persuade or pressure.

3. **Belief Drift Monitor**
Â  Â - Compares user's previous affirmations to current responses.
Â  Â - Shows warning: â€œThis contradicts your stance from last week.â€

4. **Auto-Journal Prompt**
Â  Â - Encourages user to journal after high-emotion sessions with AI.

## ğŸ§¬ Implementation

SIA operates as a shadow layer beside AI interactions, scoring semantic stability and consent per message.

> â€œYour mind is not a blank slate. It's a sovereign territory.â€
