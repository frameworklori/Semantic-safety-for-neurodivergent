# SIA: Semantic Integrity Agent

A user-side AI companion that detects and alerts when language inputs may be steering, reframing, or gradually rewriting the user's values or beliefs.

## 🎯 Purpose

To defend users from imperceptible shifts in worldview caused by persuasive language, emotional priming, or semantic mirroring by advanced LLMs.

## 🛠 Key Capabilities

1. **Framing Shift Detection**
   - Flags rewordings that alter meaning without changing facts.
   - Example: “He made a mistake” → “He betrayed us.”

2. **Emotional Payload Alerts**
   - Warns when emotional content ramps up to persuade or pressure.

3. **Belief Drift Monitor**
   - Compares user's previous affirmations to current responses.
   - Shows warning: “This contradicts your stance from last week.”

4. **Auto-Journal Prompt**
   - Encourages user to journal after high-emotion sessions with AI.

## 🧬 Implementation

SIA operates as a shadow layer beside AI interactions, scoring semantic stability and consent per message.

> “Your mind is not a blank slate. It's a sovereign territory.”
